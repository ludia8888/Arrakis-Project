#!/opt/homebrew/bin/python3.12
"""
üö® COMPLETE ALERTING SYSTEM SETUP
===================================
ÏôÑÏ†ÑÌïú ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶à ÏïåÎûå Î∞è ÏïåÎ¶º ÏãúÏä§ÌÖú Íµ¨Ï∂ï

- Prometheus ÏÑ§Ï†ï ÏàòÏ†ï (Ïò¨Î∞îÎ•∏ Ìè¨Ìä∏)
- Alertmanager ÏôÑÏ†Ñ Íµ¨ÏÑ±
- Redis/Postgres Exporter ÌôúÏÑ±Ìôî
- ÏïåÎûå Í∑úÏπô ÏÉùÏÑ±
- Îã§Ï§ë ÏïåÎ¶º Ï±ÑÎÑê ÏÑ§Ï†ï
"""

import os
import yaml
import json
import requests
import subprocess
from pathlib import Path
from datetime import datetime
import asyncio
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class CompleteAlertingSystem:
    def __init__(self):
        self.base_path = Path("/Users/isihyeon/Desktop/Arrakis-Project")
        self.monitoring_path = self.base_path / "ontology-management-service/monitoring"
        self.results = {}
        
    def fix_prometheus_config(self):
        """Prometheus ÏÑ§Ï†ï ÏàòÏ†ï - Ïò¨Î∞îÎ•∏ Ìè¨Ìä∏Î°ú ÏóÖÎç∞Ïù¥Ìä∏"""
        print("üîß Prometheus ÏÑ§Ï†ï ÏàòÏ†ï...")
        
        prometheus_config = {
            'global': {
                'scrape_interval': '15s',
                'evaluation_interval': '15s',
                'external_labels': {
                    'monitor': 'oms-cluster',
                    'environment': 'production'
                }
            },
            'alerting': {
                'alertmanagers': [{
                    'static_configs': [{
                        'targets': ['localhost:9093']
                    }]
                }]
            },
            'rule_files': [
                "/etc/prometheus/rules/*.yml",
                "/etc/prometheus/rules/enterprise_resilience_alerts.yml"
            ],
            'scrape_configs': [
                # Ïã§Ï†ú Ïã§Ìñâ Ï§ëÏù∏ MSA ÏÑúÎπÑÏä§Îì§
                {
                    'job_name': 'user-service',
                    'static_configs': [{
                        'targets': ['host.docker.internal:8012']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                {
                    'job_name': 'oms-service', 
                    'static_configs': [{
                        'targets': ['host.docker.internal:8010']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                {
                    'job_name': 'audit-service',
                    'static_configs': [{
                        'targets': ['host.docker.internal:8011']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                # Node Exporter (ÏãúÏä§ÌÖú Î©îÌä∏Î¶≠)
                {
                    'job_name': 'node-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9100']
                    }]
                },
                # Redis Exporter
                {
                    'job_name': 'redis-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9121']
                    }]
                },
                # Postgres Exporter
                {
                    'job_name': 'postgres-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9187']
                    }]
                },
                # Jaeger
                {
                    'job_name': 'jaeger',
                    'static_configs': [{
                        'targets': ['localhost:14269']
                    }]
                }
            ]
        }
        
        # ÏÑ§Ï†ï ÌååÏùº Ï†ÄÏû•
        config_path = self.monitoring_path / "prometheus/prometheus-fixed.yml"
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            yaml.dump(prometheus_config, f, default_flow_style=False)
        
        print(f"  ‚úÖ Prometheus ÏÑ§Ï†ï Ï†ÄÏû•: {config_path}")
        return config_path
    
    def create_alerting_rules(self):
        """ÏïåÎûå Í∑úÏπô ÏÉùÏÑ±"""
        print("üìã ÏïåÎûå Í∑úÏπô ÏÉùÏÑ±...")
        
        alerting_rules = {
            'groups': [
                {
                    'name': 'msa_service_alerts',
                    'rules': [
                        {
                            'alert': 'ServiceDown',
                            'expr': 'up == 0',
                            'for': '1m',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Service {{ $labels.job }} is down',
                                'description': 'Service {{ $labels.job }} has been down for more than 1 minute.'
                            }
                        },
                        {
                            'alert': 'HighErrorRate',
                            'expr': 'rate(http_requests_total{status=~"5.."}[5m]) > 0.1',
                            'for': '2m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High error rate detected',
                                'description': 'Error rate is {{ $value }} for service {{ $labels.job }}'
                            }
                        },
                        {
                            'alert': 'HighResponseTime',
                            'expr': 'histogram_quantile(0.95, http_request_duration_seconds_bucket) > 2',
                            'for': '5m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High response time',
                                'description': '95th percentile response time is {{ $value }}s for {{ $labels.job }}'
                            }
                        },
                        {
                            'alert': 'LowDiskSpace',
                            'expr': '(node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10',
                            'for': '5m',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Low disk space',
                                'description': 'Disk space is {{ $value }}% on {{ $labels.instance }}'
                            }
                        },
                        {
                            'alert': 'HighMemoryUsage',
                            'expr': '(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85',
                            'for': '5m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High memory usage',
                                'description': 'Memory usage is {{ $value }}% on {{ $labels.instance }}'
                            }
                        },
                        {
                            'alert': 'DatabaseConnectionFailure',
                            'expr': 'pg_up == 0',
                            'for': '30s',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Database connection failure',
                                'description': 'PostgreSQL database is unreachable'
                            }
                        }
                    ]
                }
            ]
        }
        
        rules_path = self.monitoring_path / "prometheus/rules/alerting_rules.yml"
        rules_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(rules_path, 'w') as f:
            yaml.dump(alerting_rules, f, default_flow_style=False)
        
        print(f"  ‚úÖ ÏïåÎûå Í∑úÏπô Ï†ÄÏû•: {rules_path}")
        return rules_path
    
    def create_alertmanager_config(self):
        """Alertmanager ÏÑ§Ï†ï ÏÉùÏÑ±"""
        print("üö® Alertmanager ÏÑ§Ï†ï ÏÉùÏÑ±...")
        
        alertmanager_config = {
            'global': {
                'smtp_smarthost': 'localhost:587',
                'smtp_from': 'alerts@arrakis-project.com',
                'slack_api_url': 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            },
            'route': {
                'group_by': ['alertname'],
                'group_wait': '10s',
                'group_interval': '10s',
                'repeat_interval': '1h',
                'receiver': 'web.hook'
            },
            'receivers': [
                {
                    'name': 'web.hook',
                    'webhook_configs': [{
                        'url': 'http://localhost:8080/webhook/alerts',
                        'send_resolved': True
                    }],
                    'email_configs': [{
                        'to': 'admin@arrakis-project.com',
                        'subject': 'üö® Arrakis Alert: {{ .GroupLabels.alertname }}',
                        'body': '''
Alert: {{ .GroupLabels.alertname }}
Severity: {{ .CommonLabels.severity }}
Summary: {{ .CommonAnnotations.summary }}
Description: {{ .CommonAnnotations.description }}

Time: {{ .FireTime }}
                        '''
                    }],
                    'slack_configs': [{
                        'channel': '#alerts',
                        'title': 'üö® Arrakis Production Alert',
                        'text': '{{ .CommonAnnotations.summary }}'
                    }]
                }
            ]
        }
        
        config_path = self.monitoring_path / "alertmanager/alertmanager-complete.yml"
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            yaml.dump(alertmanager_config, f, default_flow_style=False)
        
        print(f"  ‚úÖ Alertmanager ÏÑ§Ï†ï Ï†ÄÏû•: {config_path}")
        return config_path
    
    def create_webhook_server(self):
        """ÏõπÌõÖ ÏïåÎ¶º ÏÑúÎ≤Ñ ÏÉùÏÑ±"""
        print("üîó ÏõπÌõÖ ÏïåÎ¶º ÏÑúÎ≤Ñ ÏÉùÏÑ±...")
        
        webhook_server = '''#!/opt/homebrew/bin/python3.12
"""
üö® ALERTING WEBHOOK SERVER
ÏõπÌõÖÏùÑ ÌÜµÌïú Ïã§ÏãúÍ∞Ñ ÏïåÎ¶º Ï≤òÎ¶¨
"""

from fastapi import FastAPI, Request
import uvicorn
import json
import logging
from datetime import datetime
import asyncio
import smtplib
from email.mime.text import MIMEText

app = FastAPI(title="Arrakis Alerting Webhook")

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.post("/webhook/alerts")
async def handle_alerts(request: Request):
    """Alertmanager ÏõπÌõÖ Ï≤òÎ¶¨"""
    try:
        data = await request.json()
        
        for alert in data.get('alerts', []):
            alert_name = alert.get('labels', {}).get('alertname', 'Unknown')
            severity = alert.get('labels', {}).get('severity', 'unknown')
            status = alert.get('status', 'unknown')
            
            logger.info(f"üö® Alert: {alert_name} | Severity: {severity} | Status: {status}")
            
            # ÏΩòÏÜîÏóê Ïã§ÏãúÍ∞Ñ Ï∂úÎ†•
            print(f"""
{'='*60}
üö® ARRAKIS PRODUCTION ALERT
{'='*60}
Alert: {alert_name}
Severity: {severity.upper()}
Status: {status.upper()}
Time: {datetime.now().isoformat()}
Summary: {alert.get('annotations', {}).get('summary', 'N/A')}
Description: {alert.get('annotations', {}).get('description', 'N/A')}
{'='*60}
            """)
            
            # Slack ÏãúÎÆ¨Î†àÏù¥ÏÖò (Ïã§Ï†úÎ°úÎäî Slack API Ìò∏Ï∂ú)
            await send_slack_notification(alert_name, severity, status)
            
            # Ïù¥Î©îÏùº ÏïåÎ¶º (ÏÑ†ÌÉùÏ†Å)
            if severity == 'critical':
                await send_email_alert(alert_name, alert)
        
        return {"status": "ok", "processed": len(data.get('alerts', []))}
        
    except Exception as e:
        logger.error(f"ÏõπÌõÖ Ï≤òÎ¶¨ Ïò§Î•ò: {e}")
        return {"status": "error", "message": str(e)}

async def send_slack_notification(alert_name: str, severity: str, status: str):
    """Slack ÏïåÎ¶º ÏãúÎÆ¨Î†àÏù¥ÏÖò"""
    emoji = "üî¥" if severity == "critical" else "üü°" if severity == "warning" else "üîµ"
    print(f"üì± Slack ÏïåÎ¶º: {emoji} {alert_name} - {severity.upper()}")

async def send_email_alert(alert_name: str, alert: dict):
    """Ïù¥Î©îÏùº ÏïåÎ¶º (Ï§ëÏöî ÏïåÎûåÎßå)"""
    print(f"üìß Ïù¥Î©îÏùº ÏïåÎ¶º: {alert_name} - CRITICAL ALERT")

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "alerting-webhook"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080)
'''
        
        webhook_path = self.base_path / "alerting_webhook_server.py"
        with open(webhook_path, 'w') as f:
            f.write(webhook_server)
        
        # Ïã§Ìñâ Í∂åÌïú Î∂ÄÏó¨
        os.chmod(webhook_path, 0o755)
        
        print(f"  ‚úÖ ÏõπÌõÖ ÏÑúÎ≤Ñ ÏÉùÏÑ±: {webhook_path}")
        return webhook_path
    
    def create_docker_compose_complete(self):
        """ÏôÑÏ†ÑÌïú Docker Compose ÏÑ§Ï†ï ÏÉùÏÑ±"""
        print("üê≥ ÏôÑÏ†ÑÌïú Docker Compose ÏÉùÏÑ±...")
        
        compose_config = {
            'version': '3.8',
            'services': {
                'prometheus': {
                    'image': 'prom/prometheus:latest',
                    'container_name': 'oms-prometheus-complete',
                    'ports': ['9091:9090'],
                    'volumes': [
                        './prometheus/prometheus-fixed.yml:/etc/prometheus/prometheus.yml:ro',
                        './prometheus/rules:/etc/prometheus/rules:ro',
                        'prometheus-data:/prometheus'
                    ],
                    'command': [
                        '--config.file=/etc/prometheus/prometheus.yml',
                        '--storage.tsdb.path=/prometheus',
                        '--web.console.libraries=/usr/share/prometheus/console_libraries',
                        '--web.console.templates=/usr/share/prometheus/consoles',
                        '--web.enable-lifecycle',
                        '--web.enable-admin-api'
                    ],
                    'restart': 'unless-stopped'
                },
                'alertmanager': {
                    'image': 'prom/alertmanager:latest',
                    'container_name': 'oms-alertmanager-complete',
                    'ports': ['9093:9093'],
                    'volumes': [
                        './alertmanager/alertmanager-complete.yml:/etc/alertmanager/alertmanager.yml:ro',
                        'alertmanager-data:/alertmanager'
                    ],
                    'command': [
                        '--config.file=/etc/alertmanager/alertmanager.yml',
                        '--storage.path=/alertmanager',
                        '--web.external-url=http://localhost:9093'
                    ],
                    'restart': 'unless-stopped'
                },
                'redis-exporter': {
                    'image': 'oliver006/redis_exporter:latest',
                    'container_name': 'oms-redis-exporter',
                    'ports': ['9121:9121'],
                    'environment': [
                        'REDIS_ADDR=host.docker.internal:6379'
                    ],
                    'restart': 'unless-stopped'
                },
                'postgres-exporter': {
                    'image': 'prometheuscommunity/postgres-exporter:latest',
                    'container_name': 'oms-postgres-exporter',
                    'ports': ['9187:9187'],
                    'environment': [
                        'DATA_SOURCE_NAME=postgresql://oms_user:oms_password@host.docker.internal:5432/oms_db?sslmode=disable'
                    ],
                    'restart': 'unless-stopped'
                },
                'node-exporter': {
                    'image': 'prom/node-exporter:latest',
                    'container_name': 'oms-node-exporter-complete',
                    'ports': ['9100:9100'],
                    'volumes': [
                        '/proc:/host/proc:ro',
                        '/sys:/host/sys:ro',
                        '/:/rootfs:ro'
                    ],
                    'command': [
                        '--path.procfs=/host/proc',
                        '--path.sysfs=/host/sys',
                        '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
                    ],
                    'restart': 'unless-stopped'
                }
            },
            'volumes': {
                'prometheus-data': None,
                'alertmanager-data': None
            }
        }
        
        compose_path = self.monitoring_path / "docker-compose-complete-alerting.yml"
        
        with open(compose_path, 'w') as f:
            yaml.dump(compose_config, f, default_flow_style=False)
        
        print(f"  ‚úÖ ÏôÑÏ†ÑÌïú Docker Compose Ï†ÄÏû•: {compose_path}")
        return compose_path
    
    def test_current_services(self):
        """ÌòÑÏû¨ Ïã§Ìñâ Ï§ëÏù∏ ÏÑúÎπÑÏä§Îì§ Î©îÌä∏Î¶≠ ÌÖåÏä§Ìä∏"""
        print("üß™ ÌòÑÏû¨ ÏÑúÎπÑÏä§ Î©îÌä∏Î¶≠ ÌÖåÏä§Ìä∏...")
        
        services_to_test = [
            ("User Service", "http://localhost:8012/metrics"),
            ("OMS Service", "http://localhost:8010/metrics"),
            ("Audit Service", "http://localhost:8011/metrics"),
            ("Node Exporter", "http://localhost:9100/metrics")
        ]
        
        results = {}
        
        for service_name, url in services_to_test:
            try:
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    metrics_count = len([line for line in response.text.split('\n') if line.startswith('#')])
                    results[service_name] = {"status": "‚úÖ", "metrics": metrics_count}
                    print(f"  ‚úÖ {service_name}: {metrics_count} Î©îÌä∏Î¶≠ ÌÉÄÏûÖ")
                else:
                    results[service_name] = {"status": "‚ùå", "error": f"HTTP {response.status_code}"}
                    print(f"  ‚ùå {service_name}: HTTP {response.status_code}")
            except Exception as e:
                results[service_name] = {"status": "‚ùå", "error": str(e)}
                print(f"  ‚ùå {service_name}: {e}")
        
        return results
    
    async def setup_complete_alerting(self):
        """ÏôÑÏ†ÑÌïú ÏïåÎûå ÏãúÏä§ÌÖú ÏÑ§Ï†ï"""
        print("üö® COMPLETE ALERTING SYSTEM SETUP")
        print("=" * 60)
        
        # 1. ÌòÑÏû¨ ÏÑúÎπÑÏä§ ÌÖåÏä§Ìä∏
        service_results = self.test_current_services()
        
        # 2. Prometheus ÏÑ§Ï†ï ÏàòÏ†ï
        prometheus_config = self.fix_prometheus_config()
        
        # 3. ÏïåÎûå Í∑úÏπô ÏÉùÏÑ±
        alert_rules = self.create_alerting_rules()
        
        # 4. Alertmanager ÏÑ§Ï†ï
        alertmanager_config = self.create_alertmanager_config()
        
        # 5. ÏõπÌõÖ ÏÑúÎ≤Ñ ÏÉùÏÑ±
        webhook_server = self.create_webhook_server()
        
        # 6. ÏôÑÏ†ÑÌïú Docker Compose
        docker_compose = self.create_docker_compose_complete()
        
        print("\nüéØ ÏÑ§Ï†ï ÏôÑÎ£å Í≤∞Í≥º:")
        print(f"‚úÖ Prometheus ÏÑ§Ï†ï: {prometheus_config}")
        print(f"‚úÖ ÏïåÎûå Í∑úÏπô: {alert_rules}")
        print(f"‚úÖ Alertmanager ÏÑ§Ï†ï: {alertmanager_config}")
        print(f"‚úÖ ÏõπÌõÖ ÏÑúÎ≤Ñ: {webhook_server}")
        print(f"‚úÖ Docker Compose: {docker_compose}")
        
        print("\nüöÄ Îã§Ïùå Îã®Í≥Ñ:")
        print("1. ÏõπÌõÖ ÏÑúÎ≤Ñ ÏãúÏûë: python3 alerting_webhook_server.py")
        print("2. ÏôÑÏ†ÑÌïú Î™®ÎãàÌÑ∞ÎßÅ Ïä§ÌÉù ÏãúÏûë:")
        print("   cd ontology-management-service/monitoring")
        print("   docker-compose -f docker-compose-complete-alerting.yml up -d")
        print("3. Prometheus ÏÑ§Ï†ï Ïû¨Î°úÎìú")
        print("4. ÏïåÎûå ÌÖåÏä§Ìä∏")
        
        return {
            "service_metrics": service_results,
            "prometheus_config": str(prometheus_config),
            "alert_rules": str(alert_rules),
            "alertmanager_config": str(alertmanager_config),
            "webhook_server": str(webhook_server),
            "docker_compose": str(docker_compose)
        }

async def main():
    system = CompleteAlertingSystem()
    results = await system.setup_complete_alerting()
    
    # Í≤∞Í≥º Ï†ÄÏû•
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    result_file = f"complete_alerting_setup_{timestamp}.json"
    
    with open(result_file, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ ÏÑ§Ï†ï Í≤∞Í≥º Ï†ÄÏû•: {result_file}")
    
    return results

if __name__ == "__main__":
    results = asyncio.run(main())