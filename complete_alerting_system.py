#!/opt/homebrew/bin/python3.12
"""
ğŸš¨ COMPLETE ALERTING SYSTEM SETUP
===================================
ì™„ì „í•œ ì—”í„°í”„ë¼ì´ì¦ˆ ì•ŒëŒ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

- Prometheus ì„¤ì • ìˆ˜ì • (ì˜¬ë°”ë¥¸ í¬íŠ¸)
- Alertmanager ì™„ì „ êµ¬ì„±
- Redis/Postgres Exporter í™œì„±í™”
- ì•ŒëŒ ê·œì¹™ ìƒì„±
- ë‹¤ì¤‘ ì•Œë¦¼ ì±„ë„ ì„¤ì •
"""

import os
import yaml
import json
import requests
import subprocess
from pathlib import Path
from datetime import datetime
import asyncio
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class CompleteAlertingSystem:
    def __init__(self):
        self.base_path = Path("/Users/isihyeon/Desktop/Arrakis-Project")
        self.monitoring_path = self.base_path / "ontology-management-service/monitoring"
        self.results = {}
        
    def fix_prometheus_config(self):
        """Prometheus ì„¤ì • ìˆ˜ì • - ì˜¬ë°”ë¥¸ í¬íŠ¸ë¡œ ì—…ë°ì´íŠ¸"""
        print("ğŸ”§ Prometheus ì„¤ì • ìˆ˜ì •...")
        
        prometheus_config = {
            'global': {
                'scrape_interval': '15s',
                'evaluation_interval': '15s',
                'external_labels': {
                    'monitor': 'oms-cluster',
                    'environment': 'production'
                }
            },
            'alerting': {
                'alertmanagers': [{
                    'static_configs': [{
                        'targets': ['localhost:9093']
                    }]
                }]
            },
            'rule_files': [
                "/etc/prometheus/rules/*.yml",
                "/etc/prometheus/rules/enterprise_resilience_alerts.yml"
            ],
            'scrape_configs': [
                # ì‹¤ì œ ì‹¤í–‰ ì¤‘ì¸ MSA ì„œë¹„ìŠ¤ë“¤
                {
                    'job_name': 'user-service',
                    'static_configs': [{
                        'targets': ['host.docker.internal:8012']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                {
                    'job_name': 'oms-service', 
                    'static_configs': [{
                        'targets': ['host.docker.internal:8010']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                {
                    'job_name': 'audit-service',
                    'static_configs': [{
                        'targets': ['host.docker.internal:8011']
                    }],
                    'scrape_interval': '5s',
                    'metrics_path': '/metrics'
                },
                # Node Exporter (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)
                {
                    'job_name': 'node-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9100']
                    }]
                },
                # Redis Exporter
                {
                    'job_name': 'redis-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9121']
                    }]
                },
                # Postgres Exporter
                {
                    'job_name': 'postgres-exporter',
                    'static_configs': [{
                        'targets': ['localhost:9187']
                    }]
                },
                # Jaeger
                {
                    'job_name': 'jaeger',
                    'static_configs': [{
                        'targets': ['localhost:14269']
                    }]
                }
            ]
        }
        
        # ì„¤ì • íŒŒì¼ ì €ì¥
        config_path = self.monitoring_path / "prometheus/prometheus-fixed.yml"
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            yaml.dump(prometheus_config, f, default_flow_style=False)
        
        print(f"  âœ… Prometheus ì„¤ì • ì €ì¥: {config_path}")
        return config_path
    
    def create_alerting_rules(self):
        """ì•ŒëŒ ê·œì¹™ ìƒì„±"""
        print("ğŸ“‹ ì•ŒëŒ ê·œì¹™ ìƒì„±...")
        
        alerting_rules = {
            'groups': [
                {
                    'name': 'msa_service_alerts',
                    'rules': [
                        {
                            'alert': 'ServiceDown',
                            'expr': 'up == 0',
                            'for': '1m',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Service {{ $labels.job }} is down',
                                'description': 'Service {{ $labels.job }} has been down for more than 1 minute.'
                            }
                        },
                        {
                            'alert': 'HighErrorRate',
                            'expr': 'rate(http_requests_total{status=~"5.."}[5m]) > 0.1',
                            'for': '2m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High error rate detected',
                                'description': 'Error rate is {{ $value }} for service {{ $labels.job }}'
                            }
                        },
                        {
                            'alert': 'HighResponseTime',
                            'expr': 'histogram_quantile(0.95, http_request_duration_seconds_bucket) > 2',
                            'for': '5m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High response time',
                                'description': '95th percentile response time is {{ $value }}s for {{ $labels.job }}'
                            }
                        },
                        {
                            'alert': 'LowDiskSpace',
                            'expr': '(node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10',
                            'for': '5m',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Low disk space',
                                'description': 'Disk space is {{ $value }}% on {{ $labels.instance }}'
                            }
                        },
                        {
                            'alert': 'HighMemoryUsage',
                            'expr': '(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85',
                            'for': '5m',
                            'labels': {
                                'severity': 'warning'
                            },
                            'annotations': {
                                'summary': 'High memory usage',
                                'description': 'Memory usage is {{ $value }}% on {{ $labels.instance }}'
                            }
                        },
                        {
                            'alert': 'DatabaseConnectionFailure',
                            'expr': 'pg_up == 0',
                            'for': '30s',
                            'labels': {
                                'severity': 'critical'
                            },
                            'annotations': {
                                'summary': 'Database connection failure',
                                'description': 'PostgreSQL database is unreachable'
                            }
                        }
                    ]
                }
            ]
        }
        
        rules_path = self.monitoring_path / "prometheus/rules/alerting_rules.yml"
        rules_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(rules_path, 'w') as f:
            yaml.dump(alerting_rules, f, default_flow_style=False)
        
        print(f"  âœ… ì•ŒëŒ ê·œì¹™ ì €ì¥: {rules_path}")
        return rules_path
    
    def create_alertmanager_config(self):
        """Alertmanager ì„¤ì • ìƒì„±"""
        print("ğŸš¨ Alertmanager ì„¤ì • ìƒì„±...")
        
        alertmanager_config = {
            'global': {
                'smtp_smarthost': 'localhost:587',
                'smtp_from': 'alerts@arrakis-project.com',
                'slack_api_url': 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
            },
            'route': {
                'group_by': ['alertname'],
                'group_wait': '10s',
                'group_interval': '10s',
                'repeat_interval': '1h',
                'receiver': 'web.hook'
            },
            'receivers': [
                {
                    'name': 'web.hook',
                    'webhook_configs': [{
                        'url': 'http://localhost:8080/webhook/alerts',
                        'send_resolved': True
                    }],
                    'email_configs': [{
                        'to': 'admin@arrakis-project.com',
                        'subject': 'ğŸš¨ Arrakis Alert: {{ .GroupLabels.alertname }}',
                        'body': '''
Alert: {{ .GroupLabels.alertname }}
Severity: {{ .CommonLabels.severity }}
Summary: {{ .CommonAnnotations.summary }}
Description: {{ .CommonAnnotations.description }}

Time: {{ .FireTime }}
                        '''
                    }],
                    'slack_configs': [{
                        'channel': '#alerts',
                        'title': 'ğŸš¨ Arrakis Production Alert',
                        'text': '{{ .CommonAnnotations.summary }}'
                    }]
                }
            ]
        }
        
        config_path = self.monitoring_path / "alertmanager/alertmanager-complete.yml"
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w') as f:
            yaml.dump(alertmanager_config, f, default_flow_style=False)
        
        print(f"  âœ… Alertmanager ì„¤ì • ì €ì¥: {config_path}")
        return config_path
    
    def create_webhook_server(self):
        """ì›¹í›… ì•Œë¦¼ ì„œë²„ ìƒì„±"""
        print("ğŸ”— ì›¹í›… ì•Œë¦¼ ì„œë²„ ìƒì„±...")
        
        webhook_server = '''#!/opt/homebrew/bin/python3.12
"""
ğŸš¨ ALERTING WEBHOOK SERVER
ì›¹í›…ì„ í†µí•œ ì‹¤ì‹œê°„ ì•Œë¦¼ ì²˜ë¦¬
"""

from fastapi import FastAPI, Request
import uvicorn
import json
import logging
from datetime import datetime
import asyncio
import smtplib
from email.mime.text import MIMEText

app = FastAPI(title="Arrakis Alerting Webhook")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.post("/webhook/alerts")
async def handle_alerts(request: Request):
    """Alertmanager ì›¹í›… ì²˜ë¦¬"""
    try:
        data = await request.json()
        
        for alert in data.get('alerts', []):
            alert_name = alert.get('labels', {}).get('alertname', 'Unknown')
            severity = alert.get('labels', {}).get('severity', 'unknown')
            status = alert.get('status', 'unknown')
            
            logger.info(f"ğŸš¨ Alert: {alert_name} | Severity: {severity} | Status: {status}")
            
            # ì½˜ì†”ì— ì‹¤ì‹œê°„ ì¶œë ¥
            print(f"""
{'='*60}
ğŸš¨ ARRAKIS PRODUCTION ALERT
{'='*60}
Alert: {alert_name}
Severity: {severity.upper()}
Status: {status.upper()}
Time: {datetime.now().isoformat()}
Summary: {alert.get('annotations', {}).get('summary', 'N/A')}
Description: {alert.get('annotations', {}).get('description', 'N/A')}
{'='*60}
            """)
            
            # Slack ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” Slack API í˜¸ì¶œ)
            await send_slack_notification(alert_name, severity, status)
            
            # ì´ë©”ì¼ ì•Œë¦¼ (ì„ íƒì )
            if severity == 'critical':
                await send_email_alert(alert_name, alert)
        
        return {"status": "ok", "processed": len(data.get('alerts', []))}
        
    except Exception as e:
        logger.error(f"ì›¹í›… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"status": "error", "message": str(e)}

async def send_slack_notification(alert_name: str, severity: str, status: str):
    """Slack ì•Œë¦¼ ì‹œë®¬ë ˆì´ì…˜"""
    emoji = "ğŸ”´" if severity == "critical" else "ğŸŸ¡" if severity == "warning" else "ğŸ”µ"
    print(f"ğŸ“± Slack ì•Œë¦¼: {emoji} {alert_name} - {severity.upper()}")

async def send_email_alert(alert_name: str, alert: dict):
    """ì´ë©”ì¼ ì•Œë¦¼ (ì¤‘ìš” ì•ŒëŒë§Œ)"""
    print(f"ğŸ“§ ì´ë©”ì¼ ì•Œë¦¼: {alert_name} - CRITICAL ALERT")

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "alerting-webhook"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080)
'''
        
        webhook_path = self.base_path / "alerting_webhook_server.py"
        with open(webhook_path, 'w') as f:
            f.write(webhook_server)
        
        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
        os.chmod(webhook_path, 0o755)
        
        print(f"  âœ… ì›¹í›… ì„œë²„ ìƒì„±: {webhook_path}")
        return webhook_path
    
    def create_docker_compose_complete(self):
        """ì™„ì „í•œ Docker Compose ì„¤ì • ìƒì„±"""
        print("ğŸ³ ì™„ì „í•œ Docker Compose ìƒì„±...")
        
        compose_config = {
            'version': '3.8',
            'services': {
                'prometheus': {
                    'image': 'prom/prometheus:latest',
                    'container_name': 'oms-prometheus-complete',
                    'ports': ['9091:9090'],
                    'volumes': [
                        './prometheus/prometheus-fixed.yml:/etc/prometheus/prometheus.yml:ro',
                        './prometheus/rules:/etc/prometheus/rules:ro',
                        'prometheus-data:/prometheus'
                    ],
                    'command': [
                        '--config.file=/etc/prometheus/prometheus.yml',
                        '--storage.tsdb.path=/prometheus',
                        '--web.console.libraries=/usr/share/prometheus/console_libraries',
                        '--web.console.templates=/usr/share/prometheus/consoles',
                        '--web.enable-lifecycle',
                        '--web.enable-admin-api'
                    ],
                    'restart': 'unless-stopped'
                },
                'alertmanager': {
                    'image': 'prom/alertmanager:latest',
                    'container_name': 'oms-alertmanager-complete',
                    'ports': ['9093:9093'],
                    'volumes': [
                        './alertmanager/alertmanager-complete.yml:/etc/alertmanager/alertmanager.yml:ro',
                        'alertmanager-data:/alertmanager'
                    ],
                    'command': [
                        '--config.file=/etc/alertmanager/alertmanager.yml',
                        '--storage.path=/alertmanager',
                        '--web.external-url=http://localhost:9093'
                    ],
                    'restart': 'unless-stopped'
                },
                'redis-exporter': {
                    'image': 'oliver006/redis_exporter:latest',
                    'container_name': 'oms-redis-exporter',
                    'ports': ['9121:9121'],
                    'environment': [
                        'REDIS_ADDR=host.docker.internal:6379'
                    ],
                    'restart': 'unless-stopped'
                },
                'postgres-exporter': {
                    'image': 'prometheuscommunity/postgres-exporter:latest',
                    'container_name': 'oms-postgres-exporter',
                    'ports': ['9187:9187'],
                    'environment': [
                        'DATA_SOURCE_NAME=postgresql://oms_user:oms_password@host.docker.internal:5432/oms_db?sslmode=disable'
                    ],
                    'restart': 'unless-stopped'
                },
                'node-exporter': {
                    'image': 'prom/node-exporter:latest',
                    'container_name': 'oms-node-exporter-complete',
                    'ports': ['9100:9100'],
                    'volumes': [
                        '/proc:/host/proc:ro',
                        '/sys:/host/sys:ro',
                        '/:/rootfs:ro'
                    ],
                    'command': [
                        '--path.procfs=/host/proc',
                        '--path.sysfs=/host/sys',
                        '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
                    ],
                    'restart': 'unless-stopped'
                }
            },
            'volumes': {
                'prometheus-data': None,
                'alertmanager-data': None
            }
        }
        
        compose_path = self.monitoring_path / "docker-compose-complete-alerting.yml"
        
        with open(compose_path, 'w') as f:
            yaml.dump(compose_config, f, default_flow_style=False)
        
        print(f"  âœ… ì™„ì „í•œ Docker Compose ì €ì¥: {compose_path}")
        return compose_path
    
    def test_current_services(self):
        """í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì„œë¹„ìŠ¤ë“¤ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª í˜„ì¬ ì„œë¹„ìŠ¤ ë©”íŠ¸ë¦­ í…ŒìŠ¤íŠ¸...")
        
        services_to_test = [
            ("User Service", "http://localhost:8012/metrics"),
            ("OMS Service", "http://localhost:8010/metrics"),
            ("Audit Service", "http://localhost:8011/metrics"),
            ("Node Exporter", "http://localhost:9100/metrics")
        ]
        
        results = {}
        
        for service_name, url in services_to_test:
            try:
                response = requests.get(url, timeout=5)
                if response.status_code == 200:
                    metrics_count = len([line for line in response.text.split('\n') if line.startswith('#')])
                    results[service_name] = {"status": "âœ…", "metrics": metrics_count}
                    print(f"  âœ… {service_name}: {metrics_count} ë©”íŠ¸ë¦­ íƒ€ì…")
                else:
                    results[service_name] = {"status": "âŒ", "error": f"HTTP {response.status_code}"}
                    print(f"  âŒ {service_name}: HTTP {response.status_code}")
            except Exception as e:
                results[service_name] = {"status": "âŒ", "error": str(e)}
                print(f"  âŒ {service_name}: {e}")
        
        return results
    
    async def setup_complete_alerting(self):
        """ì™„ì „í•œ ì•ŒëŒ ì‹œìŠ¤í…œ ì„¤ì •"""
        print("ğŸš¨ COMPLETE ALERTING SYSTEM SETUP")
        print("=" * 60)
        
        # 1. í˜„ì¬ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
        service_results = self.test_current_services()
        
        # 2. Prometheus ì„¤ì • ìˆ˜ì •
        prometheus_config = self.fix_prometheus_config()
        
        # 3. ì•ŒëŒ ê·œì¹™ ìƒì„±
        alert_rules = self.create_alerting_rules()
        
        # 4. Alertmanager ì„¤ì •
        alertmanager_config = self.create_alertmanager_config()
        
        # 5. ì›¹í›… ì„œë²„ ìƒì„±
        webhook_server = self.create_webhook_server()
        
        # 6. ì™„ì „í•œ Docker Compose
        docker_compose = self.create_docker_compose_complete()
        
        print("\nğŸ¯ ì„¤ì • ì™„ë£Œ ê²°ê³¼:")
        print(f"âœ… Prometheus ì„¤ì •: {prometheus_config}")
        print(f"âœ… ì•ŒëŒ ê·œì¹™: {alert_rules}")
        print(f"âœ… Alertmanager ì„¤ì •: {alertmanager_config}")
        print(f"âœ… ì›¹í›… ì„œë²„: {webhook_server}")
        print(f"âœ… Docker Compose: {docker_compose}")
        
        print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. ì›¹í›… ì„œë²„ ì‹œì‘: python3 alerting_webhook_server.py")
        print("2. ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘:")
        print("   cd ontology-management-service/monitoring")
        print("   docker-compose -f docker-compose-complete-alerting.yml up -d")
        print("3. Prometheus ì„¤ì • ì¬ë¡œë“œ")
        print("4. ì•ŒëŒ í…ŒìŠ¤íŠ¸")
        
        return {
            "service_metrics": service_results,
            "prometheus_config": str(prometheus_config),
            "alert_rules": str(alert_rules),
            "alertmanager_config": str(alertmanager_config),
            "webhook_server": str(webhook_server),
            "docker_compose": str(docker_compose)
        }

async def main():
    system = CompleteAlertingSystem()
    results = await system.setup_complete_alerting()
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    result_file = f"complete_alerting_setup_{timestamp}.json"
    
    with open(result_file, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ì„¤ì • ê²°ê³¼ ì €ì¥: {result_file}")
    
    return results

if __name__ == "__main__":
    results = asyncio.run(main())